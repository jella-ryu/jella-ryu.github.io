---
layout: post
title: "Model Calibration"
category: "Machine Learning" 
tags: [ML, Model Retraining]
comments: true
published: true
---

## Model Calibrationì´ë€?

- Model Calibration('ëª¨ë¸ ë³´ì •'ì´ë¼ê³  í•´ì„ë¨)ì€ ì˜ˆì¸¡ëœ í™•ë¥ ì´ë‚˜ ê²°ê³¼ì˜ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ì¡°ì •í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì…ë‹ˆë‹¤.
- ì˜ˆë¥¼ ë“¤ì–´, ëª¨ë¸ì´ 1 í´ë˜ìŠ¤ì¼ í™•ë¥ ì´ 0.8 ì´ë¼ê³  ì˜ˆì¸¡í–ˆë‹¤ë©´, ì‹¤ì œë¡œ 80% ê²½ìš°ì—ì„œ 1 í´ë˜ìŠ¤ì—¬ì•¼ ì˜ ë³´ì •ëœ ê²ƒì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ë³´ì •ì„ í†µí•´ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ì‹ ë¢°í•  ìˆ˜ ìˆê³  í•´ì„ ê°€ëŠ¥í•œì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- Miscalibrated Modelì„ ì‹ë³„í•˜ê¸° ìœ„í•´ ë³´í†µ Calibration Curveë¥¼ ê·¸ë¦¬ê±°ë‚˜, Brier Score ê°™ì€ ì •ëŸ‰ì  ì§€í‘œë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

---

## miscalibrated modelì„ ì‹ë³„í•˜ëŠ” ë²•

### 1. Calibration Curve
- ì´ ê·¸ë˜í”„ëŠ” ëª¨ë¸ì—ì„œ ì˜ˆì¸¡í•œ í™•ë¥ (Predicted Probability)ì„ ì‹¤ì œ ê´€ì¸¡ëœ ì´ë²¤íŠ¸ì˜ ë¹ˆë„(Observed Frequency)ì™€ ë¹„êµí•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤. ì˜ˆì¸¡ í™•ë¥ ì´ ì‹¤ì¸¡ ë°ì´í„°ì˜ ë¹ˆë„ì™€ ì¼ì¹˜í•˜ëŠ” ëŒ€ê°ì„ ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì˜ ë³´ì •ëœ ê²ƒì…ë‹ˆë‹¤.
- ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ â€œì •í™•ë„ ì¸¡ë©´ì—ì„œì˜ ì‹ ë¢°ë„â€ë¥¼ í‰ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

##### ğŸ‘‰ ê·¸ë˜í”„ ìƒì„± ê³¼ì •
1. ì˜ˆì¸¡ í™•ë¥ ì„ binsë¡œ ë‚˜ëˆ” (ë³´í†µ 10ê°œ ì •ë„ì˜ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ”)
2. ê° binì— ëŒ€í•´:
   - xì¶•: í•´ë‹¹ binì˜ í‰ê·  ì˜ˆì¸¡ í™•ë¥ 
   - yì¶•: í•´ë‹¹ binì—ì„œ ì‹¤ì œ ì–‘ì„±(positive) í´ë˜ìŠ¤ì˜ ë¹„ìœ¨ ê³„ì‚°
3. ì´ ì ë“¤ì„ ì—°ê²°í•˜ì—¬ ê³¡ì„  ìƒì„±

```python
from sklearn.calibration import calibration_curve

def plot_calibration_curve(df, true_col, pred_col, model_name):

    y_true = df[true_col]
    y_pred = df[pred_col]
    
    prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=30, strategy='quantile') # ë°ì´í„°ì— ë”°ë¼ bin í¬ê¸° ìë™ì¡°ì ˆ
    plt.plot(prob_pred, prob_true, marker='o', label=model_name)
    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')  # Ideal calibration line

# ê° ëª¨ë¸ì˜ Calibration Curveë¥¼ ê·¸ë¦¬ê¸°
plt.figure(figsize=(8, 6))
plot_calibration_curve(df, true_col='label', pred_col='prob_ver1', model_name="Model 1")
plot_calibration_curve(df, true_col='label', pred_col='prob_ver2', model_name="Model 2")
plt.xlabel("Predicted Probability")
plt.ylabel("Observed Frequency")
plt.legend()
plt.title("Calibration Curves")
plt.show()
```

##### ğŸ‘‰ ê·¸ë˜í”„ í•´ì„ 
- ì ë“¤ì´ ëŒ€ê°ì„  ìœ„ì— ìˆìœ¼ë©´ ëª¨ë¸ì´ Underconfident â†’ ì‹¤ì œ ê°€ëŠ¥ì„±ë³´ë‹¤ ë‚®ì€ í™•ë¥ ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ê³ ,
- ë°˜ëŒ€ë¡œ ì ë“¤ì´ ëŒ€ê°ì„  ì•„ë˜ì— ìˆìœ¼ë©´ ëª¨ë¸ì´ Overconfident â†’ ë†’ì€ í™•ë¥ ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
- ì•„ë˜ ì˜ˆì‹œì—ì„œ ì£¼í™©ìƒ‰ ëª¨ë¸ì´ ì˜ ë³´ì •ëœ ê²½ìš°ì…ë‹ˆë‹¤.j

![Curve Example](/images/calibration.png)

---

### 2. Brier Score
- Calibration metric ìœ¼ë¡œ Brier score ê°™ì€ ì •ëŸ‰ì  ì§€í‘œë¥¼ í•¨ê»˜ ê³„ì‚°í•˜ì—¬ ê·¸ë˜í”„ì˜ ê²°ê³¼ë¥¼ ìˆ˜ì¹˜ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
- Brier scoreëŠ” ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì‚¬ìš©ë˜ë©°, ì˜ˆì¸¡ í™•ë¥ ê°’ê³¼ ì‹¤ì œ ê²°ê³¼ ê°„ì˜ í‰ê·  ì œê³± ì˜¤ì°¨ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ê°’ì´ ì‘ì„ìˆ˜ë¡ ë³´ì •ì´ ì˜ ëœ ëª¨ë¸ì…ë‹ˆë‹¤. ğŸ‘‰ ì¦‰, í™•ë¥ ì  ì •í™•ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
- 0ì— ê°€ê¹Œìš´ ê°’ì€ ì™„ë²½í•œ ì˜ˆì¸¡ì„ ë‚˜íƒ€ë‚´ë©°, 1ì— ê°€ê¹Œìš´ ê°’ì€ ì˜ˆì¸¡ì˜ ì •í™•ë„ê°€ ë‚®ë‹¤ëŠ” ê²ƒì„ ëœ»í•©ë‹ˆë‹¤.

```python
from sklearn.metrics import brier_score_loss

# Brier Score ê³„ì‚°
brier_model1 = brier_score_loss(df['label'], df['prob_ver1'])
brier_model2 = brier_score_loss(df['label'], df['prob_ver2'])

print(f"Brier Score (Model 1): {brier_model1:.4f}")
print(f"Brier Score (Model 2): {brier_model2:.4f}")
```